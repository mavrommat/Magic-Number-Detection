{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0b2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import gaussian_kde\n",
    "from pprint import pprint\n",
    "from scipy.integrate import simpson\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from random import sample, seed\n",
    "import random\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c2bf412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from get_magic_numbers import get_magic_numbers_main\n",
    "\n",
    "from string_magic_numbers import magic_strings_detection as string_values_process\n",
    "from sign_violation_magic_numbers import sign_violation_magic_numbers as opposite_sign_process\n",
    "from distance_based_magic_numbers import delta_distributed_magic_numbers \n",
    "from identical_magic_numbers import identical_column_magic_numbers as all_values_are_same\n",
    "from magic_dictionaries import magic_dictionary, add_to_master_dict, safe_concatenate\n",
    "from magic_dictionaries import clean_magic_results\n",
    "from density_plot import plot_data_density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbf67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_data(\n",
    "        mean, \n",
    "        sigma, \n",
    "        num_samples=1000, \n",
    "        random_seed=None, \n",
    "        magic_values=[-999, 999],\n",
    "        quantities=[100, 50], \n",
    "        col_names=\"synthetic_col\"):\n",
    "\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # --- 1. Calculate Clipping Bounds (HARDCODED 3-SIGMA) ---\n",
    "    # We hardcode the sigma_limit to 3.0 to maintain the 99.7% geometry.\n",
    "    SIGMA_LIMIT = 3.0  \n",
    "    lower_bound = mean - SIGMA_LIMIT * sigma\n",
    "    upper_bound = mean + SIGMA_LIMIT * sigma\n",
    "    \n",
    "    # --- 2. Generate and Clip the Main Normal Distribution Samples ---\n",
    "    \n",
    "    # Generate the initial samples\n",
    "    synthetic_col = np.random.normal(mean, sigma, num_samples)\n",
    "    \n",
    "    # Apply 3-sigma clipping to ensure the normal data is within the 99.7% range\n",
    "    synthetic_col = np.clip(synthetic_col, a_min=lower_bound, a_max=upper_bound)\n",
    "\n",
    "    # --- 3. Add Magic Values (Original behavior: total size increases) ---\n",
    "\n",
    "    if len(magic_values) != len(quantities):\n",
    "        raise ValueError(\"Length of magic_values must match length of quantities\")\n",
    "    \n",
    "    # If no magic values, return just the normal distribution\n",
    "    if len(magic_values) == 0:\n",
    "        df = pd.DataFrame({col_names: synthetic_col})\n",
    "        return df\n",
    "    \n",
    "    # Add magic values to the dataset\n",
    "    for magic_value, quantity in zip(magic_values, quantities):\n",
    "        magic_samples = np.full(quantity, magic_value)\n",
    "        # This is where the array size increases:\n",
    "        synthetic_col = np.concatenate((synthetic_col, magic_samples))\n",
    "    \n",
    "    # Shuffle the final array\n",
    "    np.random.shuffle(synthetic_col)\n",
    "    \n",
    "    # Create DataFrame AFTER the loop\n",
    "    df = pd.DataFrame({col_names: synthetic_col})\n",
    "    return df\n",
    "\n",
    "# Note: If you use the parameters quantities=[100, 50] and num_samples=1000,\n",
    "# the final dataset will have 1000 + 100 + 50 = 1150 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b26e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_validation(master_dict, expected_magic_numbers, tol=1e-6):\n",
    "    dist = master_dict.get('synthetic_col', {}).get('magic_distanced_numbers', [])\n",
    "    opp = master_dict.get('synthetic_col', {}).get('magic_opp_sign_numbers', [])\n",
    "    \n",
    "    detected = np.unique(np.concatenate([np.array(dist), np.array(opp)]))\n",
    "    expected = np.array(expected_magic_numbers)\n",
    "    \n",
    "    # Classification metrics\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    # Count matches\n",
    "    for exp_num in expected:\n",
    "        if any(abs(exp_num - det) < tol for det in detected):\n",
    "            true_positives += 1\n",
    "        else:\n",
    "            false_negatives += 1\n",
    "    \n",
    "    # Count false positives\n",
    "    for det_num in detected:\n",
    "        if not any(abs(det_num - exp) < tol for exp in expected):\n",
    "            false_positives += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'true_positives': true_positives,\n",
    "        'false_positives': false_positives, \n",
    "        'false_negatives': false_negatives,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'detected_count': len(detected),\n",
    "        'expected_count': len(expected)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f2a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7232e99af44af69a5c2aa60c7512aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running parameter sweep:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m_s0-50_G0-1_o0-100_d0-100_g0.0-50.0_n1000_rd10000.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------- PARAMETER GRIDS ---------------- #\n",
    "sigmas = np.linspace(0.0, 50.0, 1000)\n",
    "gauss_thresholds = np.linspace(0.0, 1.0, 1000)\n",
    "overlap_thresholds = np.linspace(0.0, 100.0, 1000)\n",
    "center_distances = np.linspace(0.0, 100.0, 1000)\n",
    "pair_gaps = np.linspace(0.0, 50.0, 1000)\n",
    "num_samples = np.linspace(1, 1000, 1000)\n",
    "num_samples = num_samples.astype(int)  \n",
    "\n",
    "quantities = [50, 25]\n",
    "\n",
    "rd_samples = 10000\n",
    "\n",
    "seed(42)\n",
    "\n",
    "\n",
    "# ---------------- PARAMETER SAMPLING ---------------- #\n",
    "param_combos = [\n",
    "    (\n",
    "        random.choice(sigmas), \n",
    "        random.choice(gauss_thresholds), \n",
    "        random.choice(overlap_thresholds), \n",
    "        random.choice(center_distances), \n",
    "        random.choice(pair_gaps),\n",
    "        random.choice(num_samples)\n",
    "    )\n",
    "    for _ in range(rd_samples)\n",
    "]\n",
    "\n",
    "def generate_filename(sigmas, gauss_thresholds, overlap_thresholds, center_distances, num_samples, pair_gaps, rd_samples):\n",
    "    sigma_range = f\"{sigmas.min():.0f}-{sigmas.max():.0f}\"\n",
    "    gth_range = f\"{gauss_thresholds.min():.0f}-{gauss_thresholds.max():.0f}\"\n",
    "    oth_range = f\"{overlap_thresholds.min():.0f}-{overlap_thresholds.max():.0f}\"\n",
    "    D_range = f\"{center_distances.min():.0f}-{center_distances.max():.0f}\"\n",
    "    gap_range = f\"{pair_gaps.min()}-{pair_gaps.max()}\"\n",
    "    num_range = f\"{num_samples.max()}\"\n",
    "    \n",
    "    return f\"2m_s{sigma_range}_G{gth_range}_o{oth_range}_d{D_range}_g{gap_range}_n{num_range}_rd{rd_samples}\"\n",
    "\n",
    "\n",
    "# ---------------- MAIN LOOP ---------------- #\n",
    "results = []\n",
    "pbar = tqdm(param_combos, desc=\"Running parameter sweep\", total=len(param_combos))\n",
    "\n",
    "for sigma, gth, oth, D, g, num in pbar:\n",
    "    magic_values = [D, D + g]\n",
    "\n",
    "    magic_master_dict, magic_cleaned_dict = get_magic_numbers_main(\n",
    "        df=synthetic_data(mean=0, sigma=sigma, num_samples=num,\n",
    "                          magic_values=magic_values, quantities=quantities, col_names=\"synthetic_col\"),\n",
    "        extended_col_info=[('synthetic_col', 'N')],\n",
    "        sign_violation_theshold=3,\n",
    "        gauss_threshold=gth,\n",
    "        overlap_threshold=oth,\n",
    "        plot_graphs=False\n",
    "    )\n",
    "\n",
    "    metrics = enhanced_validation(magic_master_dict, magic_values)\n",
    "    f1 = metrics['f1_score'] \n",
    "\n",
    "    pbar.set_postfix({\n",
    "        \"Sigma\": f\"{sigma:.2f}\",\n",
    "        \"G_thres\": f\"{gth:.2f}\",\n",
    "        \"O_thres\": f\"{oth:.2f}\",\n",
    "        \"D\": f\"{D:.2f}\",\n",
    "        \"gap\": f\"{g:.2f}\",\n",
    "        \"Number_samples\":f\"{num:.2f}\"\n",
    "    })\n",
    "\n",
    "    results.append({\n",
    "        'sigma': sigma,\n",
    "        'gauss_threshold': gth,\n",
    "        'overlap_threshold': oth,\n",
    "        'center_distance': D,\n",
    "        'pair_gap': g,\n",
    "        'number_samples': num,\n",
    "        'recall': metrics['recall'],\n",
    "        'precision': metrics['precision'],\n",
    "        'f1_score': metrics['f1_score']\n",
    "    })\n",
    "\n",
    "    if len(results) % 100 == 0:\n",
    "        filename = generate_filename(sigmas, gauss_thresholds, overlap_thresholds, center_distances, num_samples, pair_gaps, rd_samples)\n",
    "        full_filename = f\"{filename}.csv\"\n",
    "        pd.DataFrame(results).to_csv(full_filename, index=False)\n",
    "        \n",
    "print(full_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ca1e8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdc91748801496d961af35c0f058188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running parameter sweep:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m_s0-10_g0-1_o0-100_D0-30_n1000_rd10000.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------- PARAMETER GRIDS ---------------- #\n",
    "sigmas = np.linspace(0.0, 10.0, 1000)\n",
    "gauss_thresholds = np.linspace(0.0, 1.0, 1000)\n",
    "overlap_thresholds = np.linspace(0.0, 100.0, 1000)\n",
    "center_distances = np.linspace(0.0, 30.0, 1000)\n",
    "num_samples = np.linspace(1, 1000, 1000)\n",
    "num_samples = num_samples.astype(int)\n",
    "quantities = [50]\n",
    "\n",
    "rd_samples = 10000\n",
    "\n",
    "seed(42)\n",
    "\n",
    "# ---------------- PARAMETER SAMPLING ---------------- #\n",
    "param_combos = [\n",
    "    (\n",
    "        random.choice(sigmas), \n",
    "        random.choice(gauss_thresholds), \n",
    "        random.choice(overlap_thresholds), \n",
    "        random.choice(center_distances),\n",
    "        random.choice(num_samples)\n",
    " \n",
    "    )\n",
    "    for _ in range(rd_samples)\n",
    "]\n",
    "\n",
    "def generate_filename(sigmas, gauss_thresholds, overlap_thresholds, center_distances, num_samples, rd_samples):\n",
    "    sigma_range = f\"{sigmas.min():.0f}-{sigmas.max():.0f}\"\n",
    "    gth_range = f\"{gauss_thresholds.min():.0f}-{gauss_thresholds.max():.0f}\"\n",
    "    oth_range = f\"{overlap_thresholds.min():.0f}-{overlap_thresholds.max():.0f}\"\n",
    "    D_range = f\"{center_distances.min():.0f}-{center_distances.max():.0f}\"\n",
    "    num_range = f\"{num_samples.max()}\"\n",
    "    \n",
    "    return f\"1m_s{sigma_range}_g{gth_range}_o{oth_range}_D{D_range}_n{num_range}_rd{rd_samples}\"\n",
    "\n",
    "\n",
    "# ---------------- MAIN LOOP ---------------- #\n",
    "results = []\n",
    "pbar = tqdm(param_combos, desc=\"Running parameter sweep\", total=len(param_combos))\n",
    "\n",
    "for sigma, gth, oth, D, num in pbar:\n",
    "    magic_values = [D]\n",
    "\n",
    "    magic_master_dict, magic_cleaned_dict = get_magic_numbers_main(\n",
    "        df=synthetic_data(mean=0, sigma=sigma, num_samples=num,\n",
    "                          magic_values=magic_values, quantities=quantities, col_names=\"synthetic_col\"),\n",
    "        extended_col_info=[(0, 0, 'synthetic_col', 'F18')],\n",
    "        sign_violation_theshold=3,\n",
    "        gauss_threshold=gth,\n",
    "        overlap_threshold=oth,\n",
    "        plot_graphs=False\n",
    "    )\n",
    "\n",
    "    metrics = enhanced_validation(magic_master_dict, magic_values)\n",
    "\n",
    "    pbar.set_postfix({\n",
    "        \"Sigma\": f\"{sigma:.2f}\",\n",
    "        \"G_thres\": f\"{gth:.2f}\",\n",
    "        \"O_thres\": f\"{oth:.2f}\",\n",
    "        \"D\": f\"{D:.2f}\",\n",
    "        \"Number_samples\":f\"{num:.2f}\"\n",
    "    })\n",
    "\n",
    "    results.append({\n",
    "        'sigma': sigma,\n",
    "        'gauss_threshold': gth,\n",
    "        'overlap_threshold': oth,\n",
    "        'center_distance': D,\n",
    "        'number_samples': num,\n",
    "        'recall': metrics['recall'],\n",
    "        'precision': metrics['precision'],\n",
    "        'f1_score': metrics['f1_score']\n",
    "    })\n",
    "\n",
    "    if len(results) % 100 == 0:\n",
    "        filename = generate_filename(sigmas, gauss_thresholds, overlap_thresholds, center_distances, num_samples, rd_samples)\n",
    "        full_filename = f\"{filename}.csv\"\n",
    "        pd.DataFrame(results).to_csv(full_filename, index=False)\n",
    "        \n",
    "print(full_filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827f1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "import time\n",
    "\n",
    "def mario_one_up():\n",
    "    notes = [1319, 1568, 2637, 2093, 2349, 3136, 2637]\n",
    "    durations = [100, 100, 100, 100, 100, 100, 300]\n",
    "    for n, d in zip(notes, durations):\n",
    "        winsound.Beep(n, d)\n",
    "        time.sleep(0.02)\n",
    "\n",
    "mario_one_up()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
